{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "sourceId": 7806275,
          "sourceType": "datasetVersion",
          "datasetId": 4571530
        },
        {
          "sourceId": 7812037,
          "sourceType": "datasetVersion",
          "datasetId": 4575721
        },
        {
          "sourceId": 7812392,
          "sourceType": "datasetVersion",
          "datasetId": 4576012
        }
      ],
      "dockerImageVersionId": 30664,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "source": [
        "\n",
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES\n",
        "# TO THE CORRECT LOCATION (/kaggle/input) IN YOUR NOTEBOOK,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "\n",
        "import os\n",
        "import sys\n",
        "from tempfile import NamedTemporaryFile\n",
        "from urllib.request import urlopen\n",
        "from urllib.parse import unquote, urlparse\n",
        "from urllib.error import HTTPError\n",
        "from zipfile import ZipFile\n",
        "import tarfile\n",
        "import shutil\n",
        "\n",
        "CHUNK_SIZE = 40960\n",
        "DATA_SOURCE_MAPPING = 'hasoc-englishdata:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-data-sets%2F4571530%2F7806275%2Fbundle%2Farchive.zip%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20240311%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20240311T062623Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D84410002dce646f190bf89a3d82e9c5cff7e20d445e6d7d71520cee913261455c9a5db8e2f1727943ccb2f5c7853303af175cb588c586c47b9fa26657045a5153d95fcdc4acadd170d7ad7be798f83bda6a3d2591e872881a7bc02074b95d5b5f4f4a892a72837f354d320f9dccf2a380bd175e1827c499d13bcae4098cf09803cca6b116d41c0dcf670c787e45628b8a1da27baedf8c46430d2dc0ed69087f7d3770fe0b49b6bffd31ef95437d211b9f07020ee9a72923863c8506bd08e73dde5925236052db5c93ac3f40a04562ca6e89531b55407c04cef1f4a8e3978c914e65359e97d96a8d1e3f5b9c8d581b3a8ed5cc3c178ab27cd353c50455ed03c0a,hasoc20-english:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-data-sets%2F4575721%2F7812037%2Fbundle%2Farchive.zip%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20240311%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20240311T062623Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D939be738494f85d7de64cdda54ee14a47be18afc092fe7f21482ae67ecd2acce00d049256e84c9ecd00da3e9e80c4a0e49b63ec072a19b334831870dd1207744b4f075919e9e68a189ad607cbce138129173af5da8026f41c63f1492578da7907e22bcfd4136374ebf63705ffef07064817652b648ae02446ba9dec09cce8bed9e752a4aded33195c5574ff9fad69fe893811529e23aa578b163ebc78bddbeb04225392bc306fb50101a61fc329462d892a6512e7f8109effa11a6f8096fb718b817ce7ce3f7b15a5234894eec71e41cee957bd0ce2707bea823000033e965ac0c9af54cd989fc03a6c9fd31a31e04b5f4057309e9f6a37a41958dff4811f90c,hasoc19-englishdata:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-data-sets%2F4576012%2F7812392%2Fbundle%2Farchive.zip%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20240311%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20240311T062623Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D91822775b8963a2e26dc550d6cfc4699af7c792e2644adf3da162e654351c891c52d599282db8ee15e5b4d74166e89c04c5dda97bee18ae4d41a217795c27462047a42aac37b64925490b72eeae8e82b815ff114a785fb1435800de424d6239e3bbe26182ad55f7d7ba4e08b0640fac61307c950f4de44913d6e1b0d481d03dcfa235aa3ac1f84d2857c5b6f2cbb58265076ba16dedee90a3c7f654579ede8cd96fb1db30e98dd66a7d10b07db5b4a7a17e31d8227456b146f356bda9603b4a9c79a6176caa7933bacb38bcd71441f438526c4239ba7173656bd17abbc5cf78c3cbc4da62e5ca587848e91ffacbc8ba84f51292b092793334d7b112761550c4a'\n",
        "\n",
        "KAGGLE_INPUT_PATH='/kaggle/input'\n",
        "KAGGLE_WORKING_PATH='/kaggle/working'\n",
        "KAGGLE_SYMLINK='kaggle'\n",
        "\n",
        "!umount /kaggle/input/ 2> /dev/null\n",
        "shutil.rmtree('/kaggle/input', ignore_errors=True)\n",
        "os.makedirs(KAGGLE_INPUT_PATH, 0o777, exist_ok=True)\n",
        "os.makedirs(KAGGLE_WORKING_PATH, 0o777, exist_ok=True)\n",
        "\n",
        "try:\n",
        "  os.symlink(KAGGLE_INPUT_PATH, os.path.join(\"..\", 'input'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "try:\n",
        "  os.symlink(KAGGLE_WORKING_PATH, os.path.join(\"..\", 'working'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "\n",
        "for data_source_mapping in DATA_SOURCE_MAPPING.split(','):\n",
        "    directory, download_url_encoded = data_source_mapping.split(':')\n",
        "    download_url = unquote(download_url_encoded)\n",
        "    filename = urlparse(download_url).path\n",
        "    destination_path = os.path.join(KAGGLE_INPUT_PATH, directory)\n",
        "    try:\n",
        "        with urlopen(download_url) as fileres, NamedTemporaryFile() as tfile:\n",
        "            total_length = fileres.headers['content-length']\n",
        "            print(f'Downloading {directory}, {total_length} bytes compressed')\n",
        "            dl = 0\n",
        "            data = fileres.read(CHUNK_SIZE)\n",
        "            while len(data) > 0:\n",
        "                dl += len(data)\n",
        "                tfile.write(data)\n",
        "                done = int(50 * dl / int(total_length))\n",
        "                sys.stdout.write(f\"\\r[{'=' * done}{' ' * (50-done)}] {dl} bytes downloaded\")\n",
        "                sys.stdout.flush()\n",
        "                data = fileres.read(CHUNK_SIZE)\n",
        "            if filename.endswith('.zip'):\n",
        "              with ZipFile(tfile) as zfile:\n",
        "                zfile.extractall(destination_path)\n",
        "            else:\n",
        "              with tarfile.open(tfile.name) as tarfile:\n",
        "                tarfile.extractall(destination_path)\n",
        "            print(f'\\nDownloaded and uncompressed: {directory}')\n",
        "    except HTTPError as e:\n",
        "        print(f'Failed to load (likely expired) {download_url} to path {destination_path}')\n",
        "        continue\n",
        "    except OSError as e:\n",
        "        print(f'Failed to load {download_url} to path {destination_path}')\n",
        "        continue\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wfsM5VQwMOgo",
        "outputId": "eddeef44-2d07-4735-cb41-b35b46fd0143"
      },
      "cell_type": "code",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading hasoc-englishdata, 331092 bytes compressed\n",
            "[==================================================] 331092 bytes downloaded\n",
            "Downloaded and uncompressed: hasoc-englishdata\n",
            "Downloading hasoc20-english, 325976 bytes compressed\n",
            "[==================================================] 325976 bytes downloaded\n",
            "Downloaded and uncompressed: hasoc20-english\n",
            "Downloading hasoc19-englishdata, 97428 bytes compressed\n",
            "[==================================================] 97428 bytes downloaded\n",
            "Downloaded and uncompressed: hasoc19-englishdata\n",
            "Data source import complete.\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load\n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "# Input data files are available in the read-only \"../input/\" directory\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
        "\n",
        "import os\n",
        "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))\n",
        "\n",
        "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\"\n",
        "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "execution": {
          "iopub.status.busy": "2024-03-11T05:59:44.0208Z",
          "iopub.execute_input": "2024-03-11T05:59:44.021191Z",
          "iopub.status.idle": "2024-03-11T05:59:44.034622Z",
          "shell.execute_reply.started": "2024-03-11T05:59:44.021161Z",
          "shell.execute_reply": "2024-03-11T05:59:44.033358Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A0WB1KfAMOgr",
        "outputId": "e7f4eb67-274e-4082-c54f-611217ea7491"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/kaggle/input/hasoc-englishdata/english_2021.csv\n",
            "/kaggle/input/hasoc19-englishdata/english_2019_2.tsv\n",
            "/kaggle/input/hasoc20-english/english_2020.xlsx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pd.set_option('display.max_rows', None)  # Show all rows\n",
        "pd.set_option('display.max_colwidth', None)\n",
        "pd.set_option('display.max_columns', None)  # Show all columns\n",
        "df = pd.read_csv('/kaggle/input/hasoc-englishdata/english_2021.csv')\n",
        "df2 = pd.read_excel('/kaggle/input/hasoc20-english/english_2020.xlsx')\n",
        "df3= pd.read_csv('/kaggle/input/hasoc19-englishdata/english_2019_2.tsv', sep='\\t')\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-11T05:59:44.037432Z",
          "iopub.execute_input": "2024-03-11T05:59:44.038017Z",
          "iopub.status.idle": "2024-03-11T05:59:45.142775Z",
          "shell.execute_reply.started": "2024-03-11T05:59:44.037983Z",
          "shell.execute_reply": "2024-03-11T05:59:45.14093Z"
        },
        "trusted": true,
        "id": "-mcg375BMOgs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the first few rows of the dataset\n",
        "print(df.head())\n",
        "print(df2.head())\n",
        "print(df3.head())"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-11T05:59:45.145343Z",
          "iopub.execute_input": "2024-03-11T05:59:45.145917Z",
          "iopub.status.idle": "2024-03-11T05:59:45.163775Z",
          "shell.execute_reply.started": "2024-03-11T05:59:45.14588Z",
          "shell.execute_reply": "2024-03-11T05:59:45.162321Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PCRQKE7hMOgs",
        "outputId": "b95e2463-bace-44db-df0b-d8ea68a5b241"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Unnamed: 0                       _id  \\\n",
            "0        4986  60c5d6bf5659ea5e55defa2c   \n",
            "1        3394  60c5d6bf5659ea5e55def461   \n",
            "2        1310  60c5d6bf5659ea5e55defaad   \n",
            "3        3390  60c5d6bf5659ea5e55def419   \n",
            "4        4626  60c5d6bf5659ea5e55def7fa   \n",
            "\n",
            "                                                                                                                                                                                                                                                                                                                                              text  \\\n",
            "0                                                                                                                          @wealth if you made it through this &amp;&amp; were not only able to start making money for yourself but sustain living that way all from home, fuck these companies &amp; corporate pigs. power to the people, always.   \n",
            "1                                                                                                                                                                                                                                                               Technically that's still turning back the clock, dick head https://t.co/jbKaPJmpt1   \n",
            "2  @VMBJP @BJP4Bengal @BJP4India @narendramodi @JPNadda @AmitShah @DilipGhoshBJP @RahulSinhaBJP And you're the govt?!?! Stop thinking about world media, liberal gangs or any optics whatsoever and ACT NOW already.  If this is what a person at your level is facing then shudder to think the plight of common people in Bengal. #BengalBurning   \n",
            "3                                                                                                                                                                                                                                                                                               @krtoprak_yigit Soldier of Japan Who has dick head   \n",
            "4                                                                                                                                                                                                                                                          @blueheartedly You'd be better off asking who DOESN'T think he's a sleazy shitbag lmao.   \n",
            "\n",
            "  task_1 task_2  \n",
            "0    HOF   PRFN  \n",
            "1    HOF   OFFN  \n",
            "2    NOT   NONE  \n",
            "3    HOF   OFFN  \n",
            "4    HOF   OFFN  \n",
            "              tweet_id  \\\n",
            "0  1123757263427186690   \n",
            "1  1123733301397733380   \n",
            "2  1123734094108659712   \n",
            "3  1126951188170199049   \n",
            "4  1126863510447710208   \n",
            "\n",
            "                                                                                                                                           text  \\\n",
            "0                                                    hate wen females hit ah nigga with tht bro 😂😂, I’m tryna make u my la sweety , fuck ah bro   \n",
            "1                     RT @airjunebug: When you're from the Bay but you're really a NY nigga at heart. W/ @supportcaleon https://t.co/mZ8BAYlnlf   \n",
            "2  RT @DonaldJTrumpJr: Dear Democrats: The American people aren’t stupid, they know what spying is and no amount of gaslighting will change th…   \n",
            "3                        RT @SheLoveTimothy: He ain’t on drugs he just bored. I be doing the same shit when I’m bored 😂 https://t.co/tkdjSbddET   \n",
            "4  RT @TavianJordan: Summer ‘19 I’m coming for you ! No boring shit ! Beach days, road trips, kickbacks and HOT DAYS ! I’m ready I’m ready I’m…   \n",
            "\n",
            "  task1 task2                  ID  \n",
            "0   HOF  PRFN  hasoc_2020_en_2574  \n",
            "1   HOF  PRFN  hasoc_2020_en_3627  \n",
            "2   NOT  NONE  hasoc_2020_en_3108  \n",
            "3   HOF  PRFN  hasoc_2020_en_3986  \n",
            "4   NOT  NONE  hasoc_2020_en_5152  \n",
            "        text_id  \\\n",
            "0  hasoc_en_902   \n",
            "1  hasoc_en_416   \n",
            "2  hasoc_en_207   \n",
            "3  hasoc_en_595   \n",
            "4  hasoc_en_568   \n",
            "\n",
            "                                                                                                                                                 text  \\\n",
            "0                  West Bengal Doctor Crisis: Protesting doctors agree to meet Mamata Banerjee in presence of full media even as IMA goes on strike     \n",
            "1                               68.5 million people have been forced to leave their homes.      Read more: https://wef.ch/2YQcwpk  #refugees #society   \n",
            "2                                                                                     You came, you saw .... we will look after the fort! Good luck!    \n",
            "3  We'll get Brexit delivered by October 31st.    Help build the movement that will do it  http://conservatives.com/join     #BackBoris @BorisJohnson   \n",
            "4                             Fuck you. Go back to the dark ages you cow @IBNLiveRealtime: Rapes happen because men and women interact freely: Mamata   \n",
            "\n",
            "  task_1 task_2 task_3  \n",
            "0    NOT   NONE   NONE  \n",
            "1    NOT   NONE   NONE  \n",
            "2    NOT   NONE   NONE  \n",
            "3    NOT   NONE   NONE  \n",
            "4    HOF   PRFN    UNT  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.columns)\n",
        "print(df2.columns)\n",
        "print(df3.columns)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-11T05:59:45.165665Z",
          "iopub.execute_input": "2024-03-11T05:59:45.166065Z",
          "iopub.status.idle": "2024-03-11T05:59:45.175627Z",
          "shell.execute_reply.started": "2024-03-11T05:59:45.166023Z",
          "shell.execute_reply": "2024-03-11T05:59:45.174175Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jnlt4d9uMOgt",
        "outputId": "053eaf96-5b69-40b4-be2d-07d1f0423307"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['Unnamed: 0', '_id', 'text', 'task_1', 'task_2'], dtype='object')\n",
            "Index(['tweet_id', 'text', 'task1', 'task2', 'ID'], dtype='object')\n",
            "Index(['text_id', 'text', 'task_1', 'task_2', 'task_3'], dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.drop(['Unnamed: 0','_id','task_2'], axis=1)\n",
        "df2= df2.drop(['tweet_id','task2','ID'], axis=1)\n",
        "df3= df3.drop(['text_id','task_2', 'task_3'], axis=1)\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-11T05:59:45.178974Z",
          "iopub.execute_input": "2024-03-11T05:59:45.179563Z",
          "iopub.status.idle": "2024-03-11T05:59:45.190583Z",
          "shell.execute_reply.started": "2024-03-11T05:59:45.179524Z",
          "shell.execute_reply": "2024-03-11T05:59:45.189172Z"
        },
        "trusted": true,
        "id": "CD6Qf5KQMOgt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.rename(columns={'task_1': 'label'}, inplace=True)\n",
        "df2.rename(columns={'task1': 'label'}, inplace=True)\n",
        "df3.rename(columns={'task_1': 'label'}, inplace=True)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-11T05:59:45.192244Z",
          "iopub.execute_input": "2024-03-11T05:59:45.192635Z",
          "iopub.status.idle": "2024-03-11T05:59:45.201152Z",
          "shell.execute_reply.started": "2024-03-11T05:59:45.192606Z",
          "shell.execute_reply": "2024-03-11T05:59:45.199686Z"
        },
        "trusted": true,
        "id": "fjflHxmRMOgt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Combine datasets**"
      ],
      "metadata": {
        "id": "b5KHKf_VMOgt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Concatenate DataFrames along rows\n",
        "df = pd.concat([df, df2,df3], ignore_index=True)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-11T05:59:45.203079Z",
          "iopub.execute_input": "2024-03-11T05:59:45.203466Z",
          "iopub.status.idle": "2024-03-11T05:59:45.213206Z",
          "shell.execute_reply.started": "2024-03-11T05:59:45.203436Z",
          "shell.execute_reply": "2024-03-11T05:59:45.211747Z"
        },
        "trusted": true,
        "id": "Uhn2YaKEMOgv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-11T05:59:45.215862Z",
          "iopub.execute_input": "2024-03-11T05:59:45.216331Z",
          "iopub.status.idle": "2024-03-11T05:59:45.225828Z",
          "shell.execute_reply.started": "2024-03-11T05:59:45.216298Z",
          "shell.execute_reply": "2024-03-11T05:59:45.223713Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-EOLzho9MOgv",
        "outputId": "9347ed87-3fb2-4a5c-c71a-61b89adddb14"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['text', 'label'], dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Remove duplicate rows**"
      ],
      "metadata": {
        "id": "k7b4Utm-MOgw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.drop_duplicates(inplace=True)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-11T05:59:45.227373Z",
          "iopub.execute_input": "2024-03-11T05:59:45.229159Z",
          "iopub.status.idle": "2024-03-11T05:59:45.251075Z",
          "shell.execute_reply.started": "2024-03-11T05:59:45.229095Z",
          "shell.execute_reply": "2024-03-11T05:59:45.249808Z"
        },
        "trusted": true,
        "id": "8mCFv0FyMOgw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-11T05:59:45.253379Z",
          "iopub.execute_input": "2024-03-11T05:59:45.254243Z",
          "iopub.status.idle": "2024-03-11T05:59:45.263573Z",
          "shell.execute_reply.started": "2024-03-11T05:59:45.254205Z",
          "shell.execute_reply": "2024-03-11T05:59:45.262414Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gFhNXRiAMOgw",
        "outputId": "9c3e96d6-d943-4260-82fc-03c9e4a3fcb8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(8693, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Label Encoding**"
      ],
      "metadata": {
        "id": "VR6l4KYoMOgx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "# Initialize the LabelEncoder\n",
        "label_encoder = LabelEncoder()\n",
        "\n",
        "# Fit and transform the 'label' column\n",
        "df['label'] = label_encoder.fit_transform(df['label'])\n",
        "print(df.head())  #Hate means 0"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-11T05:59:45.267834Z",
          "iopub.execute_input": "2024-03-11T05:59:45.268979Z",
          "iopub.status.idle": "2024-03-11T05:59:45.284128Z",
          "shell.execute_reply.started": "2024-03-11T05:59:45.268931Z",
          "shell.execute_reply": "2024-03-11T05:59:45.282682Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e0-Zu3o6MOgx",
        "outputId": "c18a73ab-bc93-4ffd-8f25-b15eac93e4be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                                                                                                                                                                                                                                                                                                              text  \\\n",
            "0                                                                                                                          @wealth if you made it through this &amp;&amp; were not only able to start making money for yourself but sustain living that way all from home, fuck these companies &amp; corporate pigs. power to the people, always.   \n",
            "1                                                                                                                                                                                                                                                               Technically that's still turning back the clock, dick head https://t.co/jbKaPJmpt1   \n",
            "2  @VMBJP @BJP4Bengal @BJP4India @narendramodi @JPNadda @AmitShah @DilipGhoshBJP @RahulSinhaBJP And you're the govt?!?! Stop thinking about world media, liberal gangs or any optics whatsoever and ACT NOW already.  If this is what a person at your level is facing then shudder to think the plight of common people in Bengal. #BengalBurning   \n",
            "3                                                                                                                                                                                                                                                                                               @krtoprak_yigit Soldier of Japan Who has dick head   \n",
            "4                                                                                                                                                                                                                                                          @blueheartedly You'd be better off asking who DOESN'T think he's a sleazy shitbag lmao.   \n",
            "\n",
            "   label  \n",
            "0      0  \n",
            "1      0  \n",
            "2      1  \n",
            "3      0  \n",
            "4      0  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Convert emojis to text**"
      ],
      "metadata": {
        "id": "ry39YGfsMOgy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install emoji\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-11T05:59:45.285972Z",
          "iopub.execute_input": "2024-03-11T05:59:45.287307Z",
          "iopub.status.idle": "2024-03-11T06:00:00.234646Z",
          "shell.execute_reply.started": "2024-03-11T05:59:45.287249Z",
          "shell.execute_reply": "2024-03-11T06:00:00.232589Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dacAUl8UMOgy",
        "outputId": "916f4d08-45a4-4176-9e6b-41d78d78f12c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting emoji\n",
            "  Downloading emoji-2.10.1-py2.py3-none-any.whl (421 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/421.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m174.1/421.5 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m421.5/421.5 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: emoji\n",
            "Successfully installed emoji-2.10.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import emoji\n",
        "\n",
        "# Function to demojize text\n",
        "def demojize_text(text):\n",
        "    return emoji.demojize(text)\n",
        "\n",
        "# Apply the function to the 'text' column\n",
        "df['text'] = df['text'].apply(demojize_text)\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-11T06:00:00.237135Z",
          "iopub.execute_input": "2024-03-11T06:00:00.237651Z",
          "iopub.status.idle": "2024-03-11T06:00:02.973929Z",
          "shell.execute_reply.started": "2024-03-11T06:00:00.237612Z",
          "shell.execute_reply": "2024-03-11T06:00:02.972426Z"
        },
        "trusted": true,
        "id": "LVAs-lyDMOgy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Lowercasing**"
      ],
      "metadata": {
        "id": "7xSwsExmMOgz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#make lowercase\n",
        "df['text'] = df['text'].str.lower()\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-11T06:00:02.9762Z",
          "iopub.execute_input": "2024-03-11T06:00:02.976681Z",
          "iopub.status.idle": "2024-03-11T06:00:02.998009Z",
          "shell.execute_reply.started": "2024-03-11T06:00:02.97664Z",
          "shell.execute_reply": "2024-03-11T06:00:02.996519Z"
        },
        "trusted": true,
        "id": "OxDN3_xNMOgz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Remove unwanted patterns in text**"
      ],
      "metadata": {
        "id": "Ei1wYHYXMOgz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import string\n",
        "\n",
        "\n",
        "# Remove @usernames\n",
        "df['text'] = df['text'].apply(lambda x: re.sub(r'@[^ ]+', '', x))\n",
        "\n",
        "# Remove &amp\n",
        "df['text'] = df['text'].apply(lambda x: re.sub(r'&amp', '', x))\n",
        "\n",
        "# Remove URLs from the 'text' column\n",
        "df['text'] = df['text'].apply(lambda x: re.sub(r'https?://\\S+|www\\.\\S+', '', x))\n",
        "\n",
        "#remove numbers\n",
        "df['text'] = df['text'].apply(lambda x: re.sub(r'\\d+', '', x))\n",
        "\n",
        "#remove newline character\n",
        "df['text'] = df['text'].apply(lambda x: re.sub(r'\\n', '', x))\n",
        "\n",
        "\n",
        "print(df['text'].head())"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-11T06:00:03.000106Z",
          "iopub.execute_input": "2024-03-11T06:00:03.000556Z",
          "iopub.status.idle": "2024-03-11T06:00:03.178452Z",
          "shell.execute_reply.started": "2024-03-11T06:00:03.000511Z",
          "shell.execute_reply": "2024-03-11T06:00:03.176848Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K8VP1_NsMOgz",
        "outputId": "2b185f85-1eba-4a28-845a-8678c0dadfe9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0                                                           if you made it through this ;; were not only able to start making money for yourself but sustain living that way all from home, fuck these companies ; corporate pigs. power to the people, always.\n",
            "1                                                                                                                                                                                                   technically that's still turning back the clock, dick head \n",
            "2            and you're the govt?!?! stop thinking about world media, liberal gangs or any optics whatsoever and act now already.  if this is what a person at your level is facing then shudder to think the plight of common people in bengal. #bengalburning\n",
            "3                                                                                                                                                                                                                            soldier of japan who has dick head\n",
            "4                                                                                                                                                                                      you'd be better off asking who doesn't think he's a sleazy shitbag lmao.\n",
            "Name: text, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Expand contractions**"
      ],
      "metadata": {
        "id": "DhZim2FUMOg0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install contractions\n",
        "import contractions\n",
        "\n",
        "def expand_contractions(text):\n",
        "    # Use the contractions library to expand contractions\n",
        "    expanded_text = contractions.fix(text)\n",
        "    return expanded_text\n",
        "df['text'] = df['text'].apply(lambda x: expand_contractions(x))\n",
        "print(df['text'].head())"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-11T06:00:03.180191Z",
          "iopub.execute_input": "2024-03-11T06:00:03.180579Z",
          "iopub.status.idle": "2024-03-11T06:00:18.202028Z",
          "shell.execute_reply.started": "2024-03-11T06:00:03.180541Z",
          "shell.execute_reply": "2024-03-11T06:00:18.200332Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mVgu8wHQMOg0",
        "outputId": "40ef2d5d-bd4a-4084-b686-d055e3b00aa8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting contractions\n",
            "  Downloading contractions-0.1.73-py2.py3-none-any.whl (8.7 kB)\n",
            "Collecting textsearch>=0.0.21 (from contractions)\n",
            "  Downloading textsearch-0.0.24-py2.py3-none-any.whl (7.6 kB)\n",
            "Collecting anyascii (from textsearch>=0.0.21->contractions)\n",
            "  Downloading anyascii-0.3.2-py3-none-any.whl (289 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m289.9/289.9 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pyahocorasick (from textsearch>=0.0.21->contractions)\n",
            "  Downloading pyahocorasick-2.0.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (110 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.8/110.8 kB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pyahocorasick, anyascii, textsearch, contractions\n",
            "Successfully installed anyascii-0.3.2 contractions-0.1.73 pyahocorasick-2.0.0 textsearch-0.0.24\n",
            "0                                                            if you made it through this ;; were not only able to start making money for yourself but sustain living that way all from home, fuck these companies ; corporate pigs. power to the people, always.\n",
            "1                                                                                                                                                                                                   technically that is still turning back the clock, dick head \n",
            "2            and you are the govt?!?! stop thinking about world media, liberal gangs or any optics whatsoever and act now already.  if this is what a person at your level is facing then shudder to think the plight of common people in bengal. #bengalburning\n",
            "3                                                                                                                                                                                                                             soldier of japan who has dick head\n",
            "4                                                                                                                                                                                 you would be better off asking who does not think he is a sleazy shitbag lmao.\n",
            "Name: text, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Remove punctuations**"
      ],
      "metadata": {
        "id": "GT4mtcqvMOg0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_punc1(text):\n",
        "    return text.translate(str.maketrans('','',string.punctuation.replace('#','')))\n",
        "\n",
        "df['text']=df['text'].apply(remove_punc1)\n",
        "print(df['text'].head())"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-11T06:00:18.204289Z",
          "iopub.execute_input": "2024-03-11T06:00:18.205823Z",
          "iopub.status.idle": "2024-03-11T06:00:18.301775Z",
          "shell.execute_reply.started": "2024-03-11T06:00:18.205766Z",
          "shell.execute_reply": "2024-03-11T06:00:18.300189Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o807_hDsMOg0",
        "outputId": "46e78a7b-515c-42cc-ac0e-1ce9ae191f01"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0                                                            if you made it through this  were not only able to start making money for yourself but sustain living that way all from home fuck these companies  corporate pigs power to the people always\n",
            "1                                                                                                                                                                                             technically that is still turning back the clock dick head \n",
            "2            and you are the govt stop thinking about world media liberal gangs or any optics whatsoever and act now already  if this is what a person at your level is facing then shudder to think the plight of common people in bengal #bengalburning\n",
            "3                                                                                                                                                                                                                      soldier of japan who has dick head\n",
            "4                                                                                                                                                                           you would be better off asking who does not think he is a sleazy shitbag lmao\n",
            "Name: text, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Remove stopwords**"
      ],
      "metadata": {
        "id": "sDxfjoIBMOg1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nltk"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-11T06:00:18.303621Z",
          "iopub.execute_input": "2024-03-11T06:00:18.304116Z",
          "iopub.status.idle": "2024-03-11T06:00:33.248307Z",
          "shell.execute_reply.started": "2024-03-11T06:00:18.30408Z",
          "shell.execute_reply": "2024-03-11T06:00:33.246893Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5W50AaGDMOg1",
        "outputId": "14c9d7bd-5414-464a-fbcb-73f712e8059d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.3.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2023.12.25)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "def custom_tokenize(text):\n",
        "    # Tokenize the text using the default word tokenizer\n",
        "    tokens = word_tokenize(text)\n",
        "\n",
        "    # Merge '#' and its following text into a single token\n",
        "    merged_tokens = []\n",
        "    i = 0\n",
        "    while i < len(tokens):\n",
        "        if tokens[i] == '#' and i + 1 < len(tokens):\n",
        "            merged_tokens.append('#' + tokens[i + 1])\n",
        "            i += 2\n",
        "        else:\n",
        "            merged_tokens.append(tokens[i])\n",
        "            i += 1\n",
        "\n",
        "    return merged_tokens\n",
        "\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-11T06:00:33.254358Z",
          "iopub.execute_input": "2024-03-11T06:00:33.254965Z",
          "iopub.status.idle": "2024-03-11T06:00:33.372914Z",
          "shell.execute_reply.started": "2024-03-11T06:00:33.254919Z",
          "shell.execute_reply": "2024-03-11T06:00:33.371956Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OSLD8ZeiMOg1",
        "outputId": "1f7e4b54-dfef-468d-e0d2-a7366b399aa8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "# Get the list of English stop words\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "# Function to remove stop words from text\n",
        "def remove_stop_words(text):\n",
        "    words = custom_tokenize(text)\n",
        "    filtered_words = [word for word in words if word.lower() not in stop_words]\n",
        "    return ' '.join(filtered_words)\n",
        "\n",
        "# Apply the function to the 'review_text' column\n",
        "df['text'] = df['text'].apply(remove_stop_words)\n",
        "print(df['text'].head())"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-11T06:00:33.37481Z",
          "iopub.execute_input": "2024-03-11T06:00:33.375155Z",
          "iopub.status.idle": "2024-03-11T06:00:36.050104Z",
          "shell.execute_reply.started": "2024-03-11T06:00:33.375119Z",
          "shell.execute_reply": "2024-03-11T06:00:36.04839Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jAgyk5ktMOg2",
        "outputId": "f9d3ccd7-45e5-4d33-855d-fc94e3a26532"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0                                                     made able start making money sustain living way home fuck companies corporate pigs power people always\n",
            "1                                                                                                             technically still turning back clock dick head\n",
            "2    govt stop thinking world media liberal gangs optics whatsoever act already person level facing shudder think plight common people bengal #bengalburning\n",
            "3                                                                                                                                    soldier japan dick head\n",
            "4                                                                                                              would better asking think sleazy shitbag lmao\n",
            "Name: text, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Remove non english text**"
      ],
      "metadata": {
        "id": "rXEdAWsnMOg2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "def remove_non_english(text):\n",
        "    # Replace non-English characters with an empty string\n",
        "    cleaned_text = re.sub(r'[^a-zA-Z\\s#]', '', text)\n",
        "    return cleaned_text\n",
        "\n",
        "# Assuming df is your DataFrame with a 'text' column\n",
        "df['text'] = df['text'].apply(remove_non_english)\n",
        "print(df['text'].head())"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-11T06:00:36.052558Z",
          "iopub.execute_input": "2024-03-11T06:00:36.05293Z",
          "iopub.status.idle": "2024-03-11T06:00:36.107467Z",
          "shell.execute_reply.started": "2024-03-11T06:00:36.052902Z",
          "shell.execute_reply": "2024-03-11T06:00:36.106569Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vWtH0kCTMOg2",
        "outputId": "682fc6b2-ce13-4d27-bc21-5842dbe16f53"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0                                                     made able start making money sustain living way home fuck companies corporate pigs power people always\n",
            "1                                                                                                             technically still turning back clock dick head\n",
            "2    govt stop thinking world media liberal gangs optics whatsoever act already person level facing shudder think plight common people bengal #bengalburning\n",
            "3                                                                                                                                    soldier japan dick head\n",
            "4                                                                                                              would better asking think sleazy shitbag lmao\n",
            "Name: text, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "x9VCmqpvMOg3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Remove repeated characters in words e.g noooo**"
      ],
      "metadata": {
        "id": "n702UmnIMOg3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nltk\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-11T06:00:36.108792Z",
          "iopub.execute_input": "2024-03-11T06:00:36.110346Z",
          "iopub.status.idle": "2024-03-11T06:00:51.078286Z",
          "shell.execute_reply.started": "2024-03-11T06:00:36.110291Z",
          "shell.execute_reply": "2024-03-11T06:00:51.076388Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2f21po_NMOg3",
        "outputId": "1fba5b60-d5a8-4dce-85b6-0ebbf303bd83"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.3.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2023.12.25)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "import subprocess\n",
        "\n",
        "# Download and unzip wordnet\n",
        "try:\n",
        "    nltk.data.find('wordnet.zip')\n",
        "except:\n",
        "    nltk.download('wordnet', download_dir='/kaggle/working/')\n",
        "    command = \"unzip /kaggle/working/corpora/wordnet.zip -d /kaggle/working/corpora\"\n",
        "    subprocess.run(command.split())\n",
        "    nltk.data.path.append('/kaggle/working/')\n",
        "\n",
        "# Now you can import the NLTK resources as usual\n",
        "from nltk.corpus import wordnet"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-11T06:00:51.081452Z",
          "iopub.execute_input": "2024-03-11T06:00:51.082052Z",
          "iopub.status.idle": "2024-03-11T06:00:51.12963Z",
          "shell.execute_reply.started": "2024-03-11T06:00:51.082009Z",
          "shell.execute_reply": "2024-03-11T06:00:51.12768Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7UE0z5T8MOg4",
        "outputId": "9e8be53c-94f9-457a-f5f2-ca2407d53305"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /kaggle/working/...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class RepeatReplacer(object):\n",
        "    def __init__(self):\n",
        "        self.repeat_regexp = re.compile(r'(\\w*)(\\w)\\2(\\w*)')\n",
        "        self.repl = r'\\1\\2\\3'\n",
        "\n",
        "    def replace(self, word):\n",
        "        if wordnet.synsets(word):\n",
        "            return word\n",
        "\n",
        "        repl_word = self.repeat_regexp.sub(self.repl, word)\n",
        "\n",
        "        if repl_word != word:\n",
        "            return self.replace(repl_word)\n",
        "        else:\n",
        "            return repl_word\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-11T06:00:51.131644Z",
          "iopub.execute_input": "2024-03-11T06:00:51.132008Z",
          "iopub.status.idle": "2024-03-11T06:00:51.141765Z",
          "shell.execute_reply.started": "2024-03-11T06:00:51.131979Z",
          "shell.execute_reply": "2024-03-11T06:00:51.140205Z"
        },
        "trusted": true,
        "id": "iakTVqvcMOg4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Instantiate the RepeatReplacer class\n",
        "replacer = RepeatReplacer()\n",
        "\n",
        "# Function to apply the RepeatReplacer on the 'text' column\n",
        "def apply_replacer(text):\n",
        "    words = text.split()\n",
        "    replaced_words = [replacer.replace(word) for word in words]\n",
        "    return ' '.join(replaced_words)\n",
        "\n",
        "# Apply the function to the 'text' column\n",
        "df['text'] = df['text'].apply(apply_replacer)\n",
        "\n",
        "# Display the DataFrame with cleaned text\n",
        "print(df['text'].head())"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-11T06:00:51.143349Z",
          "iopub.execute_input": "2024-03-11T06:00:51.14379Z",
          "iopub.status.idle": "2024-03-11T06:00:54.689184Z",
          "shell.execute_reply.started": "2024-03-11T06:00:51.143757Z",
          "shell.execute_reply": "2024-03-11T06:00:54.687327Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JXvil0mJMOg5",
        "outputId": "e5e7ed5c-dae7-4ad2-90fa-8834c0cca6df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0                                                     made able start making money sustain living way home fuck companies corporate pigs power people always\n",
            "1                                                                                                             technically still turning back clock dick head\n",
            "2    govt stop thinking world media liberal gangs optics whatsoever act already person level facing shudder think plight common people bengal #bengalburning\n",
            "3                                                                                                                                    soldier japan dick head\n",
            "4                                                                                                              would better asking think sleazy shitbag lmao\n",
            "Name: text, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Lemmatization**"
      ],
      "metadata": {
        "id": "eL8OkRvjMOg5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.tokenize import word_tokenize\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "\n",
        "\n",
        "\n",
        "# Function to perform lemmatization on English text\n",
        "def perform_lemmatization(text):\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    words = custom_tokenize(text)\n",
        "    lemmatized_words = [lemmatizer.lemmatize(word) for word in words]\n",
        "    lemmatized_text = ' '.join(lemmatized_words)\n",
        "    return lemmatized_text\n",
        "\n",
        "# Apply the function to the 'text' column\n",
        "df['text'] = df['text'].apply(perform_lemmatization)\n",
        "\n",
        "# Display the DataFrame with lemmatized text\n",
        "print(df['text'].head())\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-11T06:00:54.691544Z",
          "iopub.execute_input": "2024-03-11T06:00:54.691991Z",
          "iopub.status.idle": "2024-03-11T06:00:57.76745Z",
          "shell.execute_reply.started": "2024-03-11T06:00:54.691951Z",
          "shell.execute_reply": "2024-03-11T06:00:57.766579Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "urC0qP0CMOg6",
        "outputId": "8c469b46-39c4-45bb-ace2-0c25c3cfe7ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0                                                       made able start making money sustain living way home fuck company corporate pig power people always\n",
            "1                                                                                                            technically still turning back clock dick head\n",
            "2    govt stop thinking world medium liberal gang optic whatsoever act already person level facing shudder think plight common people bengal #bengalburning\n",
            "3                                                                                                                                   soldier japan dick head\n",
            "4                                                                                                             would better asking think sleazy shitbag lmao\n",
            "Name: text, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(df[df['label']==0].head())"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-11T06:00:57.768857Z",
          "iopub.execute_input": "2024-03-11T06:00:57.769426Z",
          "iopub.status.idle": "2024-03-11T06:00:57.77943Z",
          "shell.execute_reply.started": "2024-03-11T06:00:57.769396Z",
          "shell.execute_reply": "2024-03-11T06:00:57.778273Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9YprFhY3MOg7",
        "outputId": "4a6a6b6c-a843-4f82-fee6-6cde662c8127"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                                                                  text  \\\n",
            "0  made able start making money sustain living way home fuck company corporate pig power people always   \n",
            "1                                                       technically still turning back clock dick head   \n",
            "3                                                                              soldier japan dick head   \n",
            "4                                                        would better asking think sleazy shitbag lmao   \n",
            "5                                                                                                 dick   \n",
            "\n",
            "   label  \n",
            "0      0  \n",
            "1      0  \n",
            "3      0  \n",
            "4      0  \n",
            "5      0  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Tokenization**"
      ],
      "metadata": {
        "id": "KY0WF6FHOe1Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-11T06:22:32.679384Z",
          "iopub.execute_input": "2024-03-11T06:22:32.681147Z",
          "iopub.status.idle": "2024-03-11T06:22:47.55466Z",
          "shell.execute_reply.started": "2024-03-11T06:22:32.681076Z",
          "shell.execute_reply": "2024-03-11T06:22:47.553307Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T4S2PZl5MOg7",
        "outputId": "7afb4ae0-81a7-4de2-8b97-b7b13f088244"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.38.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.12.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.2)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.2)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.10.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.2.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from transformers import BertTokenizer\n",
        "\n",
        "# Load mBERT tokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased')\n",
        "\n",
        "def tokenize_long_text(text, max_length=512, stride=100):\n",
        "    tokens = []\n",
        "    for i in range(0, len(text), stride):\n",
        "        chunk = text[i:i+max_length]\n",
        "        chunk_tokens = tokenizer.encode(chunk, add_special_tokens=True)\n",
        "        tokens.extend(chunk_tokens)\n",
        "    return tokens\n",
        "\n",
        "\n",
        "# Tokenize the 'text' column with sliding window\n",
        "df['tokenized_text'] = df['text'].apply(lambda x: tokenize_long_text(x, max_length=512, stride=100))\n",
        "\n",
        "# Display the DataFrame with tokenized tweets\n",
        "print(df.head())"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-11T06:23:59.291811Z",
          "iopub.execute_input": "2024-03-11T06:23:59.292281Z",
          "iopub.status.idle": "2024-03-11T06:24:17.785265Z",
          "shell.execute_reply.started": "2024-03-11T06:23:59.292245Z",
          "shell.execute_reply": "2024-03-11T06:24:17.782917Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UF8UFxM-MOg8",
        "outputId": "3223790b-c120-49d9-8d77-dc4b9f3d756b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                                                                                                                     text  \\\n",
            "0                                                     made able start making money sustain living way home fuck company corporate pig power people always   \n",
            "1                                                                                                          technically still turning back clock dick head   \n",
            "2  govt stop thinking world medium liberal gang optic whatsoever act already person level facing shudder think plight common people bengal #bengalburning   \n",
            "3                                                                                                                                 soldier japan dick head   \n",
            "4                                                                                                           would better asking think sleazy shitbag lmao   \n",
            "\n",
            "   label  \\\n",
            "0      0   \n",
            "1      0   \n",
            "2      1   \n",
            "3      0   \n",
            "4      0   \n",
            "\n",
            "                                                                                                                                                                                                                                                                                                                              tokenized_text  \n",
            "0                                                                                                                                                                                            [101, 11019, 16197, 15148, 14293, 17920, 10846, 37879, 14625, 13170, 11816, 11005, 11263, 12100, 46666, 24109, 10240, 13183, 11426, 19540, 102]  \n",
            "1                                                                                                                                                                                                                                                                  [101, 29914, 10454, 12647, 48448, 12014, 52843, 10120, 11263, 13578, 102]  \n",
            "2  [101, 13585, 10123, 20517, 56294, 11356, 29843, 28950, 16330, 10303, 13275, 12976, 11669, 23433, 19833, 19034, 15042, 13277, 48237, 73495, 42113, 27874, 20648, 27521, 14624, 11426, 11015, 17026, 108, 11015, 17026, 35497, 10230, 102, 101, 186, 27874, 20648, 27521, 14624, 11426, 11015, 17026, 108, 11015, 17026, 35497, 10230, 102]  \n",
            "3                                                                                                                                                                                                                                                                                       [101, 50803, 33106, 10206, 10120, 11263, 13578, 102]  \n",
            "4                                                                                                                                                                                                                                 [101, 10894, 18322, 72082, 27874, 38523, 11233, 12547, 57667, 10123, 10537, 10240, 180, 10369, 10133, 102]  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Sentence embedding**"
      ],
      "metadata": {
        "id": "n1CtcVydOjAE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install fasttext"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ANAa9UFWMOg8",
        "outputId": "8306b268-170b-45d2-e3b8-e148ceb39f6b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting fasttext\n",
            "  Downloading fasttext-0.9.2.tar.gz (68 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/68.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━\u001b[0m \u001b[32m61.4/68.8 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m68.8/68.8 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pybind11>=2.2 (from fasttext)\n",
            "  Using cached pybind11-2.11.1-py3-none-any.whl (227 kB)\n",
            "Requirement already satisfied: setuptools>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from fasttext) (67.7.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from fasttext) (1.25.2)\n",
            "Building wheels for collected packages: fasttext\n",
            "  Building wheel for fasttext (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fasttext: filename=fasttext-0.9.2-cp310-cp310-linux_x86_64.whl size=4199773 sha256=863daa9e2f3cf8849927927e72fbd82f850f6065fcf0aa22d547e4303d074a91\n",
            "  Stored in directory: /root/.cache/pip/wheels/a5/13/75/f811c84a8ab36eedbaef977a6a58a98990e8e0f1967f98f394\n",
            "Successfully built fasttext\n",
            "Installing collected packages: pybind11, fasttext\n",
            "Successfully installed fasttext-0.9.2 pybind11-2.11.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import fasttext.util\n",
        "\n",
        "# Specify the path where you want to save the model\n",
        "model_path = '/content/cc.en.300.bin.gz.part'\n",
        "\n",
        "# Download the pre-trained FastText model for English\n",
        "fasttext.util.download_model('en', if_exists='ignore')\n",
        "\n",
        "# Move the downloaded model to the specified path\n",
        "os.rename('cc.en.300.bin', model_path)\n",
        "\n",
        "# Load the pre-trained model\n",
        "model = fasttext.load_model(model_path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cbtjxMd_N_G8",
        "outputId": "606cbf33-9105-4c99-c79b-a4b49523ab83"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.en.300.bin.gz\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to get the sentence vector using FastText\n",
        "def get_sentence_vector(text):\n",
        "    return model.get_sentence_vector(text)\n",
        "\n",
        "# Apply the function to the 'text' column to get sentence vectors\n",
        "df['text_vector'] = df['text'].apply(get_sentence_vector)\n"
      ],
      "metadata": {
        "id": "ISta-2wnOY6B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CkBp3AABPox3",
        "outputId": "999f2bc7-b2c8-4220-9676-97676fef6789"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                                                                                                                     text  \\\n",
            "0                                                     made able start making money sustain living way home fuck company corporate pig power people always   \n",
            "1                                                                                                          technically still turning back clock dick head   \n",
            "2  govt stop thinking world medium liberal gang optic whatsoever act already person level facing shudder think plight common people bengal #bengalburning   \n",
            "3                                                                                                                                 soldier japan dick head   \n",
            "4                                                                                                           would better asking think sleazy shitbag lmao   \n",
            "\n",
            "   label  \\\n",
            "0      0   \n",
            "1      0   \n",
            "2      1   \n",
            "3      0   \n",
            "4      0   \n",
            "\n",
            "                                                                                                                                                                                                                                                                                                                              tokenized_text  \\\n",
            "0                                                                                                                                                                                            [101, 11019, 16197, 15148, 14293, 17920, 10846, 37879, 14625, 13170, 11816, 11005, 11263, 12100, 46666, 24109, 10240, 13183, 11426, 19540, 102]   \n",
            "1                                                                                                                                                                                                                                                                  [101, 29914, 10454, 12647, 48448, 12014, 52843, 10120, 11263, 13578, 102]   \n",
            "2  [101, 13585, 10123, 20517, 56294, 11356, 29843, 28950, 16330, 10303, 13275, 12976, 11669, 23433, 19833, 19034, 15042, 13277, 48237, 73495, 42113, 27874, 20648, 27521, 14624, 11426, 11015, 17026, 108, 11015, 17026, 35497, 10230, 102, 101, 186, 27874, 20648, 27521, 14624, 11426, 11015, 17026, 108, 11015, 17026, 35497, 10230, 102]   \n",
            "3                                                                                                                                                                                                                                                                                       [101, 50803, 33106, 10206, 10120, 11263, 13578, 102]   \n",
            "4                                                                                                                                                                                                                                 [101, 10894, 18322, 72082, 27874, 38523, 11233, 12547, 57667, 10123, 10537, 10240, 180, 10369, 10133, 102]   \n",
            "\n",
            "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       text_vector  \n",
            "0                                 [0.005235608, -0.040566698, 0.038095172, 0.09205608, -0.06358238, 0.015482527, 0.036657676, -0.004955586, 0.023276778, 0.01365059, -0.0001935563, 0.007188672, 4.5864377e-05, 0.015355093, 0.001826887, 0.029665103, 0.02103038, 0.018536318, -0.024226326, 0.031513542, -0.0046274588, -0.01195943, -0.013113012, -0.024869516, -0.033464655, -0.028084002, 0.0205866, -0.013161736, -0.016104383, 0.05387132, -0.007888262, -0.030023085, 0.035296973, -0.01587823, -0.02062155, 0.006371094, -0.014600433, 0.029051563, 0.016759783, -0.02907648, -0.0071328455, -0.0057645664, 0.0067587984, 0.032536592, -0.051122665, 0.010311406, 0.0026375628, -0.03203687, -0.018412996, -0.00876534, 0.030921755, 0.0014601226, 0.012853866, -0.02341707, -0.037115883, -0.0021791542, 0.03344467, -0.037085943, -0.085294835, -0.01925151, 0.010929143, -0.019364871, -0.020614369, -0.02276502, -0.007682915, 0.014004926, -0.0067550763, 0.00749948, -0.0053659333, -0.0029844698, -0.043109458, 0.004301674, 0.010574896, -0.008896978, -0.015271739, -0.017281523, 0.00021534937, 0.052601706, -0.034697566, -0.009838395, -0.011583253, -0.015554657, -0.021931937, 0.007218682, 0.01783, 0.009545041, 0.021407781, -0.009504056, 0.026477644, 0.009034559, 0.003154573, 0.009887539, 0.031454, 0.00859606, -0.003091603, 0.020152707, 0.01021072, 0.023533551, -0.0064460235, 0.008779914, ...]  \n",
            "1                           [0.009687059, -0.0138306515, 0.016176537, 0.12010203, -0.016243901, -0.0071579837, 0.017036851, -0.02764767, 0.027969446, 0.010198738, -0.029725041, -0.007991566, -0.005492673, 0.0075482256, 0.008113116, 0.046029847, -0.0020729825, -0.006794206, -0.03542108, -0.018071948, 0.010267109, 0.0086844405, -0.0006564083, 0.008060407, 0.011516994, -0.023360936, -0.022521146, 0.00916796, -0.0036678724, 0.055214714, -0.031090725, -0.01235136, 0.026906798, 0.03156198, 0.02281751, 0.025683261, 0.010153328, 0.07491669, 0.021516833, -0.016962653, 0.011567873, -0.009115573, -0.013108436, 0.06643314, -0.04766758, -0.012743906, 0.005493476, -0.011004792, -0.027399706, 0.019115735, 0.022213487, -0.017849643, 0.015883515, -0.004366765, -0.01781791, -0.029236123, 0.018396748, -0.020600103, -0.06433472, 0.014414291, 0.017948573, 0.028337765, 0.027321732, -0.04313012, 0.0017462022, 0.009346348, -0.07098898, -0.05527348, -0.028131748, -0.038155124, -0.000959291, 0.025092853, 0.027941626, 0.023079654, -0.0037849452, 0.028588168, -0.037293125, -0.006513235, -0.03707365, -0.057521142, -0.016720274, -0.044933144, -0.05706409, 0.031302232, -0.019880975, 0.006180925, -0.011311754, -0.027551714, 0.013405832, -0.022502284, -0.006677689, -0.018598652, 0.056638516, 0.006143824, -0.008780729, 0.025644157, 0.015844308, 0.030116389, -0.0019954012, 0.039938148, ...]  \n",
            "2  [-0.03865509, 0.00025324538, 0.014567098, 0.07279781, -0.07221016, -0.01889628, 0.030569168, 0.015462541, -0.0042772894, -0.011326041, 0.0033279082, 0.012641828, -0.0059010596, -0.002753382, -0.014264919, -0.004200954, 0.011746663, -0.013687402, -0.021168096, 0.026614211, 0.019568186, 0.01523321, -0.005846477, -0.0033951215, -0.02864773, -0.016231544, 0.0019023462, -0.027139908, 0.0056282133, 0.063748255, 0.00676902, 0.014960391, 0.001539785, -0.033767525, 0.0095485905, 0.0009853338, 0.033879194, 0.0046408717, 0.00050076895, -0.0033827855, -0.0062025525, -0.0053664357, -0.001685363, 0.009549071, -0.04076424, -0.009128889, -0.010509779, -0.0011530174, -0.010046737, 0.0051985383, -0.005265275, -0.009449889, 0.0063432306, -0.007537441, -0.01886375, -0.0065169143, 0.022066405, -0.006893342, -0.062025618, -0.0153382, 0.009453053, 0.013351624, -0.016748628, -0.0023453112, 0.018615982, -0.010009326, -0.017326124, -0.014588931, -0.004057951, 0.0018906427, -0.0036515687, -0.001417919, -0.00019380273, 0.0018236935, -0.018250354, -0.021816874, 0.014191243, 0.00570894, -0.02277746, 0.016882561, -0.019051906, 0.0018668625, -0.037013162, 0.009551211, -0.008961629, -0.032641634, 0.0005561809, -0.027556451, 0.01762048, 0.03398842, 0.0014583978, 0.009226029, 0.045631494, 0.00013239186, 0.0011408183, 0.001559161, 0.019994281, 0.020827731, -0.016187215, -0.008460759, ...]  \n",
            "3                              [0.019693268, -0.015223675, 8.605607e-05, 0.035064623, -0.013900214, -0.024217444, 0.07759006, 0.014241388, 0.035349973, 0.018715683, -0.030607224, -0.0078008496, 0.008898097, 0.023655945, -0.02716754, 0.069072, -0.047740046, -0.06473194, -0.02586906, 0.013062987, -0.04399921, -0.034510728, 0.059237998, -0.00551467, -0.010324972, -0.0060252454, 0.019212928, -0.04078347, 0.012400553, 0.13227831, -0.044391774, -0.010660335, 0.041594796, 0.05676865, 0.022776851, 0.029159425, -0.022131981, 0.036806256, -0.012049533, 0.020455781, 0.006509941, 0.010185781, -0.054031223, 0.033929583, -0.08855252, -0.0054350095, 0.001858226, -0.020854477, -0.0027677417, 0.050378952, 0.01745457, -0.031290263, -0.03109243, 0.032355513, -0.005705998, -0.011976177, -0.032470644, -0.0062016062, -0.045634255, -0.026423367, 0.058359213, 0.025410555, 0.0470715, 0.003091475, -0.022324089, 0.047288783, -0.030145712, -0.003164906, -0.06275711, -0.006764289, -0.012943196, 0.03723013, -0.04981231, -0.052602075, -0.037421815, -0.0024182312, -0.010316241, -0.038230095, -0.02333083, 0.0051656133, -0.066978574, -0.01924273, -0.014033388, -0.005430947, -0.03290929, 0.0036331494, -0.028609265, -0.0034657936, 0.026641155, -0.018312141, -0.005463548, 0.031993788, 0.052719872, 0.035084594, -0.027901255, 0.014304287, 0.06182882, 0.048690144, 0.0075127846, 0.056466788, ...]  \n",
            "4                          [-0.013562076, 0.0030643928, 0.023483135, 0.061709415, -0.10194873, -0.057816286, -0.0084651, -0.03661328, 0.018895138, 0.021208288, -0.02120372, 0.0056399214, -0.011282647, 0.024132017, -0.004506241, 0.013501349, 0.033535026, 0.035976898, -0.04068668, 0.04047894, -0.014521163, -0.0025107074, 0.0020776903, -0.0054517975, -0.05578837, -0.04167884, 0.017283065, 0.00930612, -0.0033509834, 0.072498225, -0.01704928, 0.0069350274, -0.011184793, 0.0385017, 0.01546004, 0.0020970174, 0.028960735, -0.010761971, -0.026375286, 0.003535264, -0.019569589, 0.014182398, -0.009630836, 0.019458048, 0.006606418, 0.010270973, 0.0229952, 0.02179559, -0.004056273, 0.028503561, -0.01120336, 0.011221251, -0.021577338, 0.006101079, -0.017733786, -0.007942307, -0.009824941, 0.018460613, -0.0697576, -0.037378974, 0.012000399, -0.028079653, -0.014466102, -0.0065931883, -0.0070417216, 0.021863958, -0.05736194, 0.0063973977, -0.006675989, -0.044884764, -0.025472911, 0.0036627697, 0.0070052897, 0.007587248, -0.0137851145, 0.0029783272, 0.03069849, -0.0024004644, -0.021673286, 0.00012461776, -4.44507e-05, -0.04189609, -0.0064815157, 0.012767549, -0.025095457, 0.0062157665, 0.0005270706, 0.019870985, 0.010223801, 0.020740047, 0.0044961516, 0.03228353, 0.11222799, -0.012761657, 0.0012817708, -0.010085049, -0.032237664, 0.034790836, -0.014846281, 0.017574368, ...]  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Convert to csv**"
      ],
      "metadata": {
        "id": "Kt9ZqQllPiL2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.to_csv('english_preprocessed.csv', index=False)\n"
      ],
      "metadata": {
        "id": "IEJ8O2_KPCOF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}